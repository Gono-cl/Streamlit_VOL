import streamlit as st
from datetime import datetime
import numpy as np
import pandas as pd
import altair as alt
import time
from ProcessOptimizer import Optimizer
from core.utils.export_tools import export_to_csv, export_to_excel
from core.utils import db_handler
from core.hardware.opc_communication import OPCClient
from core.hardware.experimental_run import ExperimentRunner
from core.utils.logger import StreamlitLogger
import sys
import os
import json
import dill as pickle

# --- Save/Resume Section ---
SAVE_DIR = "resumable_multiobjective_runs"
os.makedirs(SAVE_DIR, exist_ok=True)

# --- Page Title ---
st.title("Multi-Objective Optimization")

# --- Sidebar Simulation Toggle and OPC URL ---
sim_mode_label = {
    "off": " Real Hardware (Full)",
    "hybrid": "Hybrid (Simulated Measurement)",
    "full": "Full Simulation (No Hardware)"
}
simulation_mode = st.sidebar.selectbox("Experiment Mode", options=["off", "hybrid", "full"], format_func=lambda x: sim_mode_label[x])
opc_url = st.sidebar.text_input("üîå OPC Server URL", value="http://em-nun:57080")

# --- Always initialize session state keys ---
if "simulation_mode" not in st.session_state:
    st.session_state.simulation_mode = simulation_mode
if "opc_url" not in st.session_state:
    st.session_state.opc_url = opc_url

# --- Simulation Mode Banner ---
if st.session_state.simulation_mode != "off":
    st.warning("‚ö†Ô∏è Simulation Mode is ON ‚Äî OPC hardware interaction is partially or fully disabled.")

# --- Resume Section ---
st.sidebar.markdown("---")
resume_file = st.sidebar.selectbox(
    "üîÑ Resume from Previous Multi-Objective Run",
    options=["None"] + os.listdir(SAVE_DIR)
)
if resume_file != "None" and st.sidebar.button("Load Previous Run"):
    run_path = os.path.join(SAVE_DIR, resume_file)
    with open(os.path.join(run_path, "optimizer.pkl"), "rb") as f:
        st.session_state.optimizer = pickle.load(f)
    df = pd.read_csv(os.path.join(run_path, "experiment_data.csv"))
    with open(os.path.join(run_path, "metadata.json"), "r") as f:
        metadata = json.load(f)

    # Restore session state
    st.session_state.experiment_data = df.to_dict("records")
    st.session_state.iteration = len(df)
    st.session_state.variables = metadata["variables"]
    st.session_state.objectives = metadata["objectives"]
    st.session_state.total_iterations = metadata["total_iterations"]
    st.session_state.optimization_running = True
    st.session_state.run_name = resume_file

    # --- Restore simulation_mode and opc_url from metadata ---
    st.session_state.simulation_mode = metadata.get("simulation_mode", "off")
    st.session_state.opc_url = metadata.get("opc_url", "http://em-nun:57080")

    # --- Re-initialize OPC client and runner ---
    st.session_state.opc_client = OPCClient(st.session_state.opc_url)
    st.session_state.runner = ExperimentRunner(
        st.session_state.opc_client,
        "multi_objective_log.csv",
        simulation_mode=st.session_state.simulation_mode
    )

    st.success(f"Loaded run: {resume_file}")

# --- Experiment Metadata ---
st.subheader("üß™ Experiment Metadata")
experiment_name = st.text_input("Experiment Name", value=st.session_state.get("run_name", ""))
experiment_date = st.date_input("Experiment Date", datetime.today())
experiment_notes = st.text_area("Additional Notes")

# --- Define Variables ---
st.subheader("‚öôÔ∏è Optimization Variables")

if "variables" not in st.session_state:
    st.session_state.variables = []

with st.form(key="variable_form"):
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        var_name = st.text_input("Variable Name")
    with col2:
        lower_bound = st.number_input("Lower Bound", value=0.0, format="%.4f")
    with col3:
        upper_bound = st.number_input("Upper Bound", value=1.0, format="%.4f")
    with col4:
        unit = st.text_input("Unit")

    submitted = st.form_submit_button("Add Variable")
    if submitted:
        if var_name and lower_bound < upper_bound:
            st.session_state.variables.append((var_name, lower_bound, upper_bound, unit))
        else:
            st.warning("Please enter a valid name and ensure lower < upper bound.")

# --- Display Added Variables ---
if st.session_state.variables:
    st.markdown("### üìü Added Variables")
    for i, (name, low, high, unit) in enumerate(st.session_state.variables):
        st.write(f"{i+1}. **{name}**: from {low} to {high} {unit}")
else:
    st.info("No variables added yet.")

# --- Optimization Settings ---
st.subheader("‚öôÔ∏è Optimization Settings")
col5, col6 = st.columns(2)
initial_experiments = col5.number_input("Initialization Experiments", min_value=1, max_value=100, value=5)
total_iterations = col6.number_input("Total Iterations", min_value=1, max_value=100, value=20)
OBJECTIVE_OPTIONS = [
    "Yield",
    "Normalized Area",
    "Throughput",
    "Used Organic",
    "Solvent Penalty",
    "Extraction Efficiency",
    "Space-Time Yield"
]
objectives = st.multiselect("üéØ Select Objectives to Optimize", OBJECTIVE_OPTIONS)

# --- Always keep objectives in session state ---
if "objectives" not in st.session_state or not st.session_state.objectives:
    st.session_state.objectives = objectives

st.markdown("### Select Maximize or Minimize Objective")

objective_directions = {}
for obj in objectives:
    direction = st.selectbox(
        f"Direction for **{obj}**:",
        ["maximize", "minimize"],
        key=f"{obj}_direction"
    )
    objective_directions[obj] = direction

if st.button("Start Optimization"):
    if len(objectives) < 2:
        st.error("Please select at least two objectives to perform multi-objective optimization.")
    else:
        st.session_state.optimization_running = True
        st.session_state.iteration = 0
        st.session_state.experiment_data = []
        st.session_state.simulation_mode = simulation_mode
        st.session_state.opc_url = opc_url
        st.session_state.opc_client = OPCClient(st.session_state.opc_url)
        st.session_state.runner = ExperimentRunner(st.session_state.opc_client, "multi_objective_log.csv", simulation_mode=st.session_state.simulation_mode)
        search_space = [(low, high) for _, low, high, _ in st.session_state.variables]
        n_objectives = len(objectives)
        st.session_state.objectives = objectives  # <-- Always update objectives in session state
        st.session_state.optimizer = Optimizer(
            dimensions=search_space,
            n_initial_points=initial_experiments,
            n_objectives=n_objectives
        )
        st.session_state.stop_requested = False  # Reset stop flag

# --- Optimization Loop ---
if st.session_state.get("optimization_running", False):
    # --- Stop Button ---
    if st.button("üõë Stop Experiment"):
        st.session_state.stop_requested = True

    optimizer = st.session_state.optimizer
    experiment_data = st.session_state.experiment_data
    runner = st.session_state.runner
    iteration = st.session_state.iteration
    objectives = st.session_state.objectives

    st.markdown("### üìã Optimization Log")
    # --- Live Logger Setup ---
    log_placeholder = st.empty()
    logger = StreamlitLogger(placeholder=log_placeholder)
    sys.stdout = logger 

    progress_bar = st.progress(iteration / total_iterations)
    st.markdown("### Pareto Chart")   
    pareto_chart_placeholder = st.empty()

    while iteration < total_iterations:
        if st.session_state.get("stop_requested", False):
            st.warning("Experiment stopped by user.")
            st.session_state.optimization_running = False
            st.session_state.stop_requested = False
            break

        x = optimizer.ask()
        params = {name: val for (name, *_), val in zip(st.session_state.variables, x)}
        result = runner.run_experiment(params, experiment_number=iteration + 1, total_iterations=total_iterations, objectives=objectives, directions=objective_directions)
        y_multi = [-result[obj] for obj in objectives]

        if not isinstance(y_multi, list) or len(y_multi) != len(objectives):
            st.error(f"Mismatch: expected {len(objectives)} objectives but got {len(y_multi)} in result.")
            st.stop()

        optimizer.tell(x, y_multi)

        row = {
            "Experiment #": iteration + 1,
            "Timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            **params,
            **{f"{obj}": result[obj] for obj in objectives}
        }
        experiment_data.append(row)
        df_results = pd.DataFrame(experiment_data)
        raw_csv_path = runner.save_full_measurements_to_csv(experiment_name)

        # --- Update charts inside the loop ---

        if len(objectives) == 2 and not df_results.empty:
            obj_x, obj_y = objectives[0], objectives[1]
            df_results_plot = df_results.copy()
            for obj in objectives:
                if st.session_state.get(f"{obj}_direction", "maximize") == "minimize":
                    df_results_plot[obj] = -df_results_plot[obj]
            df_pareto_calc = df_results.copy()
            for obj in objectives:
                if st.session_state.get(f"{obj}_direction", "maximize") == "minimize":
                    df_pareto_calc[obj] = -df_pareto_calc[obj]

            pareto_df = df_pareto_calc[[obj_x, obj_y]].copy().sort_values(by=obj_x, ascending=False)
            pareto_front_indices = []
            best_so_far = -np.inf
            for idx, row_ in pareto_df.iterrows():
                if row_[obj_y] > best_so_far:
                    pareto_front_indices.append(idx)
                    best_so_far = row_[obj_y]
            pareto_front_df = df_results_plot.loc[pareto_front_indices]

            x_vals = df_results_plot[obj_x]
            y_vals = df_results_plot[obj_y]
            x_range = x_vals.max() - x_vals.min()
            y_range = y_vals.max() - y_vals.min()
            x_buffer = x_range * 0.05 if x_range > 0 else 1
            y_buffer = y_range * 0.05 if y_range > 0 else 1
            x_min = x_vals.min() - x_buffer
            x_max = x_vals.max() + x_buffer
            y_min = y_vals.min() - y_buffer
            y_max = y_vals.max() + y_buffer

            chart = alt.Chart(df_results_plot).mark_circle(size=60).encode(
                x=alt.X(f"{obj_x}:Q", title=obj_x, scale=alt.Scale(domain=[x_min, x_max])),
                y=alt.Y(f"{obj_y}:Q", title=obj_y, scale=alt.Scale(domain=[y_min, y_max])),
                tooltip=list(df_results.columns)).interactive()
            pareto_line = alt.Chart(pareto_front_df).mark_line(color="red").encode(
                x=alt.X(f"{obj_x}:Q"), y=alt.Y(f"{obj_y}:Q"))

            pareto_chart_placeholder.altair_chart(chart + pareto_line, use_container_width=True)
        elif len(objectives) > 2:
            pareto_chart_placeholder.info("‚ÑπÔ∏è Pareto plot available only for 2 objectives at a time.")

        iteration += 1
        st.session_state.iteration = iteration
        st.session_state.experiment_data = experiment_data
        progress_bar.progress(iteration / total_iterations)
        time.sleep(0.5)

        # --- Save after each iteration ---
        run_name = experiment_name.strip() if experiment_name.strip() else "multiobjective_experiment"
        run_path = os.path.join(SAVE_DIR, run_name)
        os.makedirs(run_path, exist_ok=True)
        df_results.to_csv(os.path.join(run_path, "experiment_data.csv"), index=False)
        with open(os.path.join(run_path, "optimizer.pkl"), "wb") as f:
            pickle.dump(optimizer, f)
        metadata = {
            "variables": st.session_state.variables,
            "objectives": objectives,
            "total_iterations": total_iterations,
            "experiment_name": experiment_name,
            "experiment_notes": experiment_notes,
            "experiment_date": str(experiment_date),
            "simulation_mode": st.session_state.simulation_mode,
            "opc_url": st.session_state.opc_url
        }
        with open(os.path.join(run_path, "metadata.json"), "w") as f:
            json.dump(metadata, f, indent=4)

    if iteration == total_iterations:
        st.success("‚úÖ Multi-objective Optimization Complete!")
        st.session_state.optimization_running = False

        # Save results to CSV and metadata as before...

        # --- Compute Pareto front for saving ---
        if len(objectives) == 2 and not df_results.empty:
            obj_x, obj_y = objectives[0], objectives[1]
            df_pareto_calc = df_results.copy()
            for obj in objectives:
                if st.session_state.get(f"{obj}_direction", "maximize") == "minimize":
                    df_pareto_calc[obj] = -df_pareto_calc[obj]
            pareto_df = df_pareto_calc[[obj_x, obj_y]].copy().sort_values(by=obj_x, ascending=False)
            pareto_front_indices = []
            best_so_far = -np.inf
            for idx, row_ in pareto_df.iterrows():
                if row_[obj_y] > best_so_far:
                    pareto_front_indices.append(idx)
                    best_so_far = row_[obj_y]
            pareto_front_df = df_results.loc[pareto_front_indices]
            best_result = pareto_front_df.to_dict("records")
        else:
            best_result = None

        optimization_settings = {
            "initial_experiments": initial_experiments,
            "total_iterations": total_iterations,
            "objectives": objectives,
            "method": "Bayesian Multi-Objective",
            "simulation_mode": st.session_state.simulation_mode,
            "opc_url": st.session_state.opc_url
        }
        db_handler.save_experiment(
            name=experiment_name,
            notes=experiment_notes,
            variables=st.session_state.variables,
            df_results=df_results,
            best_result=best_result,
            settings=optimization_settings
        )
        st.info("All results and Pareto front saved to the database.")
